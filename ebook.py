#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# ---------------------------------------------------------------------------
# Copyright Â© 2017-2023 Brian M. Clapper
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# this program. If not, see <http://www.gnu.org/licenses/>.
# ---------------------------------------------------------------------------

import logging
import os
import re
import shutil
import sys
from collections.abc import Generator
from contextlib import chdir, contextmanager
from dataclasses import dataclass
from enum import Enum
from enum import auto as enum_auto
from glob import glob
from pathlib import Path
from string import Template
from tempfile import TemporaryDirectory
from typing import Any, Dict, Optional, Self
from typing import Sequence as Seq

import click
import yaml

# ---------------------------------------------------------------------------
# Constants
# ---------------------------------------------------------------------------

VERSION = "2.0.0"
NAME = "ebook"

LOG_LEVELS = ("DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL")

# +RTS and -RTS delimit Haskell runtime options. See
# http://www.haskell.org/ghc/docs/6.12.2/html/users_guide/runtime-control.html
#
# -Ksize sets the stack size. -K10m uses a 10 Mb stack, for instance. The
# default size is 8M.

# HASKELL_OPTS = '+RTS -K20m -RTS'
HASKELL_OPTS = ""

# Minimum Pandoc version, expressed as a (major, minor, patch) tuple
MIN_PANDOC_VERSION = (3, 1, 0)
MIN_PYTHON_VERSION = (3, 10)

INVARIANT_PANDOC_EXTENSIONS = (
    "line_blocks",
    "escaped_line_breaks",
    "smart",
    "fenced_code_blocks",
    "fenced_code_attributes",
    "backtick_code_blocks",
    "yaml_metadata_block",
    "startnum",
    "example_lists",
    "grid_tables",
    "strikeout",
)

# ---------------------------------------------------------------------------
# Data types and classes
# ---------------------------------------------------------------------------


class VersionError(Exception):
    pass


class OutputType(Enum):
    HTML = enum_auto()
    # LATEX = enum_auto()
    PDF = enum_auto()
    WORD = enum_auto()
    EPUB = enum_auto()
    AST = enum_auto()


@dataclass(frozen=True)
class SourcePaths:
    """
    Make-style sources and dependencies, calculated from the supplied book
    directory.
    """

    metadata: Optional[Path]
    author: Optional[Path]
    preface: Optional[Path]
    prologue: Optional[Path]
    epilogue: Optional[Path]
    dedication: Optional[Path]
    foreward: Optional[Path]
    afterward: Optional[Path]
    glossary: Optional[Path]
    copyright: Optional[Path]
    appendices: list[Path]
    acknowledgements: Optional[Path]
    cover_image: Optional[Path]
    references_yaml: Optional[Path]
    chapters: list[Path]
    html_css: Path
    html_pdf_css: Path
    epub_css: Path

    @property
    def all_metadata(self: Self) -> Seq[Path]:
        return [
            f for f in (self.metadata, self.references_yaml) if f is not None
        ]

    @property
    def markdown_files(self: Self) -> Seq[Path]:
        """
        Return the Markdown files for the book, in the appropriate order.
        """
        maybe_with_nones = (
            [
                self.copyright,
                self.dedication,
                self.foreward,
                self.preface,
                self.prologue,
            ]
            + self.chapters
            + [self.epilogue, self.acknowledgements]
            + self.appendices
            + [self.glossary, self.author]
        )
        return [p for p in maybe_with_nones if p is not None]


@dataclass(frozen=True)
class BuildData:
    source_paths: SourcePaths
    book_dir: Path
    build_dir: Path
    etc_dir: Path
    files_dir: Path
    scripts_dir: Path
    pandoc: Path
    temp_dir: Path
    combined_metadata: Path
    image_references: list[Path]
    html_body_include: Path
    additional_markdown_extensions: list[str]

    @property
    def markdown_files(self: Self) -> Seq[Path]:
        """
        Return the list of Markdown files to be processed.
        """
        return list(self.source_paths.markdown_files) + [
            self.combined_metadata
        ]


class BookError(Exception):
    pass


class BookToolError(BookError):
    pass


# ---------------------------------------------------------------------------
# Functions
# ---------------------------------------------------------------------------


def configure_logging(
    s_level: str, path: Optional[str] = None
) -> logging.Logger:
    """
    Configure the Python logging subsystem. The returned
    logger will log to standard output and, optionally,
    any log file specified.

    Parameters:

    s_level - the string name of the desired logging
              level (e.g., "INFO", "DEBUG")
    path    - optional path to which to log output

    Returns: the logger to use
    """
    import sys

    # See https://docs.python.org/3/howto/logging.html
    log_level: Optional[int] = getattr(logging, s_level.upper(), None)
    if log_level is None:
        raise Exception(
            f'Cannot get log level "{s_level.upper()} from ' "logging package."
        )

    formatter = logging.Formatter(
        "[%(asctime)s] (%(levelname)s) %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )
    handlers = []
    handlers.append(logging.StreamHandler(stream=sys.stdout))
    if path is not None:
        handlers.append(logging.FileHandler(filename=path, mode="w"))

    logger = logging.getLogger("main")
    # Remove all existing handlers, in case this cell is rerun.
    for h in logger.handlers:
        logger.removeHandler(h)

    # Don't propagate to the root logger.
    logger.propagate = False
    logger.setLevel(log_level)

    # install new handlers
    for h in handlers:
        h.setLevel(log_level)
        h.setFormatter(formatter)
        logger.addHandler(h)

    logger.info(f"Logging configured, at log level {s_level}.")

    return logger


def file_or_default(path: Path, default: Path) -> Path:
    """
    Return `path` if it exists, or `default` if not.

    Parameters:

    path:    path to file to test
    default: default file
    """
    if path.is_file():
        return path

    if not default.is_file():
        raise Exception(
            f"Default file {default} does not exist or is not a file."
        )

    return default


def optional_path(filename: str, dir: Path) -> Optional[Path]:
    """
    Look for the specified filename in directory <dir>, returning a Path
    object or None. The <dir> argument is second to faciliate partial
    application via functools.partial().
    """
    p = Path(dir, filename)
    return p if p.exists() and p.is_file() else None


def path_glob(pattern: str, dir: Path) -> list[Path]:
    """
    Expand the specified glob pattern in directory <dir>, returning a sequence
    of Path objects (which might be empty). The <dir> argument is second to
    faciliate partial application via functools.partial().
    """
    return list(Path(dir).glob(pattern))


def sh(command: str, logger: logging.Logger) -> None:
    """
    Runs a shell command, exiting if the command fails.

    Parameters:

    command: the command to run
    """
    import subprocess

    logger.debug(command)
    rc = subprocess.call(command, shell=True)
    if rc < 0:
        raise OSError(f"Command aborted by signal {-rc}")


def find_in_path(command: str) -> Optional[Path]:
    """
    Find a command in the path, if possible.
    """
    path = [
        Path(p) for p in os.getenv("PATH", "").split(os.pathsep) if len(p) > 0
    ]
    found = None
    for d in path:
        if not d.exists():
            continue
        p = Path(d, command)
        if p.is_file() and os.access(p, os.X_OK):
            found = p
            break

    return found


@contextmanager
def ensure_dir(
    directory: Path, autoremove: bool = False
) -> Generator[None, None, None]:
    """
    Run a block in the context of a directory that is created if it doesn't
    exist.

    Parameters:

    dir        - the directory
    autoremove - if True, remove the directory when the "with" block finishes.
    """
    try:
        directory.mkdir(parents=True, exist_ok=True)
        yield
    finally:
        if autoremove:
            if directory.exists():
                shutil.rmtree(str(directory))


def combine_metadata(tempdir: Path, sources: SourcePaths) -> Path:
    """
    Create the combined metadata YAML file and return its path.
    """

    # Load the primary metadata file, as we need to pull some things from it.
    metadata: Dict[str, str] = {}
    if sources.metadata is not None:
        with open(sources.metadata, encoding="utf-8") as f:
            metadata = yaml.safe_load(f)

    combined_metadata_path = Path(tempdir, "metadata.yaml")
    with open(combined_metadata_path, "w", encoding="utf-8") as out:
        for p in sources.all_metadata:
            if p is None:
                continue
            if not p.exists():
                continue

            out.write("---\n")
            with open(p, "r", encoding="utf-8") as f:
                for line in f.readlines():
                    out.write(line)
            out.write("...\n\n")

        # If no language was specified, add one.
        if metadata.get("language") is None:
            out.write("---\n")
            out.write("lang: en")
            out.write("...\n\n")

    return combined_metadata_path


def make_temp_text_file(name: str, contents: str, tempdir: Path) -> Path:
    """
    Write the specified contents (presumably a string with multiple lines)
    to a temporary file in the specified temporary directory, and return the
    path to the file.
    """
    path = Path(tempdir, name)
    with open(path, mode="w", encoding="utf-8") as f:
        f.write(contents)

    return path


@contextmanager
def preprocess_markdown(
    build_data: BuildData, divs: bool = False
) -> Generator[list[Path], None, None]:
    """
    Content manager that preprocesses the Markdown files, adding some content
    and producing new, individual files. These files should be used to generate
    the book, rather than the original user-supplied ones.

    Parameters:

    build_data - the build data
    divs       - True to generate a <div> with a file-based "id" attribute and
                 'class="book_section"' around each Markdown file. Only really
                 useful for HTML.

    Yields the paths to the generated files
    """
    file_without_dashes = re.compile(r"^[^a-z]*([a-z]+).*$")

    directory = Path(build_data.temp_dir, "preprocessed")
    from_to = [
        (f, Path(directory, Path(f).name)) for f in build_data.markdown_files
    ]
    generated = [t for _, t in from_to]
    with ensure_dir(directory, autoremove=True):
        for f, temp in from_to:
            with open(temp, mode="w") as t:
                basefile = f.name
                ext = f.suffix
                m = file_without_dashes.match(basefile)
                if m:
                    cls = m.group(1)
                else:
                    cls = basefile

                # Added classes to each section. Can be used in CSS.
                if divs and ext == ".md":
                    t.write(f'<div class="book_section" id="section_{cls}">\n')
                with open(f, mode="r", encoding="utf-8") as input_file:
                    for line in input_file.readlines():
                        print(line.rstrip(), file=t)

                # Force a newline after each file.
                t.write("\n")
                if divs and ext == ".md":
                    print("</div>", file=t)
                t.close()

        if build_data.source_paths.references_yaml is not None:
            # Create a temporary Markdown file (page) for the references, all
            # the way at the end, which is where Pandoc writes them.
            generated.append(
                make_temp_text_file(
                    name="references.md",
                    tempdir=build_data.temp_dir,
                    contents="# References\n",
                )
            )

        yield generated


def find_image_references(
    markdown_files: Seq[Path], bookdir: Path, logger: logging.Logger
) -> list[Path]:
    """
    Parse image references from the book's Markdown files, so they can
    be copied.

    Parameters:

    markdown_files - the files to parse, looking for image references
    bookdir        - the book directory where the images presumably reside
    logger         - the logger

    Raises an exception if an absolute path or URL is found.
    """
    from urllib.parse import urlparse

    image_pat = re.compile(r"\s*!\[.*\]\(([^\)]+)\).*")

    abort = False
    images = []
    for path in markdown_files:
        with open(path, mode="r", encoding="utf-8") as md:
            logger.debug(f'Looking at "{path}"')
            for i, line in enumerate(md.readlines()):
                lno = i + 1
                if (m := image_pat.search(line)) is None:
                    continue
                image_ref = m.group(1)
                logger.debug(
                    f"Found possible image on line {lno}: {image_ref}"
                )
                p = urlparse(image_ref)
                if (p.scheme is not None) and (p.scheme.strip() != ""):
                    # Not a local image.
                    logger.error(
                        f'Image "{image_ref}" is a URL, which is unsupported.'
                    )
                    abort = True
                    continue

                image = Path(image_ref)
                if image.is_absolute():
                    image_full_path = image
                    logger.error(
                        f'Image "{image_ref}" is an absolute path, which is '
                        "unsupported."
                    )
                    abort = True
                    continue

                image_full_path = Path(bookdir, image_ref)
                if not image_full_path.exists():
                    logger.error(
                        f'File "{path}" refers to nonexistent image '
                        f'"{image_full_path}".'
                    )
                    abort = True
                    continue

                images.append(image)

    if abort:
        raise BookError("One or more images are in error.")

    return images


def find_sources(book_dir: Path, etc_dir: Path) -> SourcePaths:
    """
    Locate all book sources
    """
    from functools import partial

    book_dir = book_dir.absolute()
    opt = partial(optional_path, dir=book_dir)
    expand = partial(path_glob, dir=book_dir)

    def local_or_default(filename: str) -> Path:
        return file_or_default(
            Path(book_dir, filename), Path(etc_dir, filename)
        )

    return SourcePaths(
        metadata=opt("metadata.yaml"),
        author=opt("author.md"),
        preface=opt("preface.md"),
        prologue=opt("prologue.md"),
        epilogue=opt("epilogue.md"),
        dedication=opt("dedication.md"),
        foreward=opt("foreward.md"),
        afterward=opt("afterward.md"),
        glossary=opt("glossary.md"),
        copyright=opt("copyright.md"),
        appendices=expand("appendix-*.md"),
        acknowledgements=opt("acknowledgements.md"),
        cover_image=opt("cover.png"),
        chapters=expand("chapter-*.md"),
        references_yaml=opt("references.yaml"),
        html_css=local_or_default("html.css"),
        html_pdf_css=local_or_default("html-pdf.css"),
        epub_css=local_or_default("epub.css"),
    )


def pandoc_options(build_data: BuildData, output_type: OutputType) -> str:
    """
    Determine the appropriate Pandoc options for a given output file type.

    Parameters:

    build_data  - the build data, used for paths
    output_type - the output type

    Returns:

    A string of command line options
    """
    extensions: set[str] = set(INVARIANT_PANDOC_EXTENSIONS)
    if build_data.additional_markdown_extensions is not None:
        extensions = extensions.union(
            set(build_data.additional_markdown_extensions)
        )

    ext_str = "+".join(extensions)
    input_format = f"markdown+{ext_str}"

    pandoc_filter = Path(build_data.scripts_dir, "pandoc-filter.py")
    common = (
        f"-f {input_format} {HASKELL_OPTS} -F {pandoc_filter} "
        "--standalone --citeproc"
    )

    head_include = Path(build_data.files_dir, "head_include.html")
    html_common = (
        f"{common} -t html "
        f"-H {head_include} -B {build_data.html_body_include} "
    )

    match output_type:
        case OutputType.HTML:
            return f"{html_common} --css {build_data.source_paths.html_css} "

        case OutputType.PDF:
            return (
                f"{html_common} --css {build_data.source_paths.html_pdf_css} "
                f"--pdf-engine=weasyprint"
            )

        case OutputType.WORD:
            ref = Path(build_data.files_dir, "custom-reference.docx")
            return f"{common} -t docx --reference-doc={ref}"

        case OutputType.EPUB:
            return (
                f"{common} -t epub --toc --split-level=1 "
                f"--css {build_data.source_paths.epub_css} "
                f"--epub-cover-image {build_data.source_paths.cover_image}"
            )

        case OutputType.AST:
            return f"{common} -t json"


def locate_pandoc(logger: logging.Logger) -> Path:
    """
    Locate pandoc in the path, and check the version. The first found
    pandoc executable is used.
    """
    import subprocess

    pandoc = find_in_path("pandoc")
    if pandoc is None:
        raise FileNotFoundError("Cannot locate pandoc executable.")

    with subprocess.Popen(
        (f"{pandoc}", "--version"), stdout=subprocess.PIPE, encoding="ascii"
    ) as p:
        stdout, _ = p.communicate()

    version_pat = re.compile(r"^\s*pandoc\s+(\d+\.\d+[\d.]*).*$")
    version = None
    for l in stdout.split("\n"):
        if (m := version_pat.search(l)) is not None:
            version = m.group(1).split(".")
            break

    if (version is None) or (len(version) < 2):
        raise BookToolError("Unable to determine pandoc version.")

    version = tuple(int(v) for v in version)
    if version[0:3] < MIN_PANDOC_VERSION:
        version_str = ".".join(str(i) for i in version)
        min_version_str = ".".join(str(i) for i in MIN_PANDOC_VERSION)
        raise BookToolError(
            f"Pandoc version is {version_str}. Version {min_version_str} or "
            "newer is required."
        )

    logger.info(f"Using pandoc: {pandoc}")
    return pandoc


def build_directory(book_dir: Path) -> Path:
    """
    Given the book directory, locate the build directory.
    """
    return Path(book_dir, "build")


def make_build_dir(build_dir: Path, logger: logging.Logger) -> None:
    """
    Create the build directory, if it doesn't exists.

    Parameters:

    build_dir - the path to the build directory
    logger    - the logger
    """
    if build_dir.exists():
        if not build_dir.is_dir():
            raise click.ClickException(
                f'Build directory "{build_dir}" already exists, but it '
                "isn't a directory."
            )
        logger.debug(f'Build directory "{build_dir}" already exists.')
    else:
        logger.debug(f'Creating directory "{build_dir}"')
        build_dir.mkdir()


def make_html_body_include(build_data: BuildData) -> None:
    """
    Create the body include for HTML output, which is where the cover page
    image (if any) goes. The output is written to build_data.html_body_include.
    If there's no cover image, then the generated file will be empty. The
    template used is in the etc/files directory (body_include.html). It's
    a string.Template-compatible template.
    """
    import base64

    with open(build_data.html_body_include, mode="w", encoding="utf-8") as out:
        if build_data.source_paths.cover_image is None:
            # Nothing to do. The template is just for a cover image. Make sure
            # there's something in the file, though.
            out.write("\n")
        else:
            with open(build_data.source_paths.cover_image, mode="rb") as img:
                image_bytes = img.read()

            b64_bytes = base64.encodebytes(image_bytes)
            b64_str = "".join(chr(b) for b in b64_bytes).replace("\n", "")
            with open(
                Path(build_data.files_dir, "body_include.html"),
                mode="r",
                encoding="utf-8",
            ) as template:
                out.write(
                    Template(template.read()).substitute(
                        {"base64_image": b64_str}
                    )
                )


def fix_epub(
    epub: Path, build_data: BuildData, book_title: str, logger: logging.Logger
) -> None:
    """
    Make some adjustments to the generated tables of contents in the ePub,
    removing empty elements and removing items matching the book title.

    Parameters:

    epub:       The path to the epub file
    book_title: The book title
    build_data: The build data
    logger:     Logger
    """
    from xml.dom import minidom
    from zipfile import ZIP_DEFLATED, ZipFile

    temp_dir = Path(build_data.temp_dir, "epub")
    if temp_dir.exists():
        shutil.rmtree(temp_dir)

    def zip_add(zf, path, zippath):
        """Swiped from zipfile module."""
        if os.path.isfile(path):
            zf.write(path, zippath, ZIP_DEFLATED)
        elif os.path.isdir(path):
            if zippath:
                zf.write(path, zippath)
            for nm in os.listdir(path):
                zip_add(zf, os.path.join(path, nm), os.path.join(zippath, nm))

    def unpack_epub() -> None:
        # Assumes pwd is *not* unpack directory.
        logger.debug(f".. Unpacking {epub}.")
        with ZipFile(epub) as z:
            z.extractall(temp_dir)

    def repack_epub() -> None:
        # Assumes pwd is *not* unpack directory.
        logger.debug(f".. Packing new {epub}.")
        with ZipFile(epub, "w") as z:
            with chdir(temp_dir):
                for f in os.listdir("."):
                    if f in ["..", "."]:
                        continue
                    zip_add(z, f, f)

    def strip_text_children(element: minidom.Element) -> None:
        for child in element.childNodes:
            if type(child) == minidom.Text:
                element.removeChild(child)

    def get_text_children(element: minidom.Element) -> Optional[str]:
        text = None
        if element:
            s = ""
            for child in element.childNodes:
                if child and (type(child) == minidom.Text):
                    s += child.data.strip()
            text = s if s else None

        return text

    def fix_toc_ncx(toc: Path) -> None:
        # Assumes pwd *is* unpack directory
        logger.debug(f'(fix_epub) Reading table of contents file "{toc}".')
        with open(toc, encoding="utf-8") as f:
            toc_xml = f.read()

        logger.debug("(fix_epub) Adjusting table of contents.")
        with minidom.parseString(toc_xml) as dom:
            nav_map = dom.getElementsByTagName("navMap")
            if not nav_map:
                raise Exception("Malformed table of contents: No <navMap>.")
            nav_map = nav_map[0]
            for p in nav_map.getElementsByTagName("navPoint"):
                text_nodes = p.getElementsByTagName("text")
                text = None
                if text_nodes:
                    text = get_text_children(text_nodes[0])

                if (not text) or (text == book_title):
                    nav_map.removeChild(p)

            # Renumber the nav points.
            for i, p in enumerate(nav_map.getElementsByTagName("navPoint")):
                num = i + 1
                p.setAttribute("id", f"navPoint-{num}")

            # Strip any text nodes from the navmap.
            strip_text_children(nav_map)

            # Write it out.
            with open(toc, mode="w", encoding="utf-8") as f:
                dom.writexml(f)

    def fix_nav_xhtml(toc: Path) -> None:
        # Assumes pwd *is* unpack directory
        logger.debug(f'(fix_epub) Reading table of contents file "{toc}".')
        with open(toc, encoding="utf8") as f:
            toc_xml = f.read()

        logger.debug("(fix_epub) Adjusting table of contents.")
        with minidom.parseString(toc_xml) as dom:
            navs = dom.getElementsByTagName("nav")
            nav = None
            for n in navs:
                if not n.hasAttributes():
                    continue
                a = n.attributes.get("id")
                if not a:
                    continue
                if a.value == "toc":
                    nav = n
                    break
            else:
                raise Exception("Malformed table of contents: No TOC <nav>.")

            ol = nav.getElementsByTagName("ol")
            if (not ol) or (len(ol) == 0):
                raise Exception(
                    "Malformed table of contents: No list in <nav>."
                )
            ol = ol[0]

            for li in ol.getElementsByTagName("li"):
                a = li.getElementsByTagName("a")
                if not a:
                    raise Exception(
                        "Malformed table of contents: No <a> in <li>."
                    )
                a = a[0]
                text = get_text_children(a)
                if (not text) or (text == book_title):
                    ol.removeChild(li)

            # Renumber the list items
            for i, li in enumerate(ol.getElementsByTagName("li")):
                num = i + 1
                li.setAttribute("id", f"toc-li-{num}")

            # Strip any text nodes from the ol.
            strip_text_children(ol)

            # Write it out.
            with open(toc, mode="w", encoding="utf-8") as f:
                dom.writexml(f)

    def fix_chapter_files() -> None:
        logger.debug("(fix_epub) Fixing titles in chapter files...")
        title_pat = re.compile(r"^(.*<title>).*(</title>).*$")

        def fix_chapter_file(path: Path, title: str) -> None:
            with open(path, encoding="utf-8") as f:
                lines = [l.rstrip() for l in f.readlines()]
            with open(path, mode="w", encoding="utf-8") as f:
                for line in lines:
                    m = title_pat.search(line)
                    if m:
                        line = f"{m.group(1)}{title}{m.group(2)}"
                    f.write(f"{line}\n")

        for file in glob("EPUB/text/ch*.xhtml"):
            fix_chapter_file(Path(file), title=book_title)

    # Main logic
    try:
        unpack_epub()
        with ensure_dir(temp_dir):
            with chdir(temp_dir):
                paths_and_funcs = (
                    (Path("EPUB", "toc.ncx"), fix_toc_ncx),
                    (Path("EPUB", "nav.xhtml"), fix_nav_xhtml),
                )
                for toc, func in paths_and_funcs:
                    if not os.path.exists(toc):
                        logger.debug(f"(fix_epub) No {toc} file. Skipping it.")
                        continue
                    func(toc)

                fix_chapter_files()

        repack_epub()
    finally:
        # rmtree(temp_dir)
        pass


def load_metadata(metadata_file: Path) -> Dict[str, Any]:
    """
    Loads a YAML metadata file, returning the loaded dictionary.

    Parameters:

    metadata_file; path to the file to load
    """
    if metadata_file.exists():
        with open(metadata_file, mode="r") as f:
            s = "".join([s for s in f if not s.startswith("---")])
            metadata = yaml.load(s, Loader=yaml.FullLoader)
    else:
        metadata = {}

    return metadata


@contextmanager
def prepare_build(
    book_dir: Path,
    etc_dir: Path,
    additional_extensions: list[str],
    logger: logging.Logger,
) -> Generator[BuildData, None, None]:
    """
    Prepare the build environment, which includes gathering sources, locating
    images, creating a temporary work directory, ensuring that the final
    build directory exists, etc.

    After the context exits, the temporary work directory is removed, so all
    build work must occur within the context.

    Parameters:

    book_dir - the directory containing the book's sources
    etc_dir  - where the support files are located
    logger   - the logger

    Yields:

    A BuildData object.
    """
    pandoc = locate_pandoc(logger)
    build_dir = build_directory(book_dir)
    make_build_dir(build_dir, logger)
    with TemporaryDirectory(prefix="ebook") as tempdir_name:
        tempdir = Path(tempdir_name)
        files_dir = Path(etc_dir, "files")
        sources = find_sources(book_dir, files_dir)
        combined_metadata = combine_metadata(tempdir=tempdir, sources=sources)
        image_references = find_image_references(
            markdown_files=sources.markdown_files,
            bookdir=book_dir,
            logger=logger,
        )
        bd = BuildData(
            source_paths=sources,
            book_dir=book_dir.absolute(),
            build_dir=build_dir.absolute(),
            etc_dir=etc_dir,
            files_dir=files_dir,
            scripts_dir=Path(etc_dir, "scripts"),
            pandoc=pandoc,
            temp_dir=tempdir,
            combined_metadata=combined_metadata,
            image_references=image_references,
            html_body_include=Path(tempdir, "body_include.html"),
            additional_markdown_extensions=additional_extensions,
        )
        make_html_body_include(bd)
        yield bd


def dump_ast(
    book_dir: Path,
    etc_dir: Path,
    additional_extensions: list[str],
    logger: logging.Logger,
) -> None:
    """
    Target: Dumps the JSON AST to the build directory.

    Parameters:

    book_dir - the directory containing the book's sources
    etc_dir  - where the support files are located
    logger   - the logger
    """
    with prepare_build(
        book_dir=book_dir,
        etc_dir=etc_dir,
        additional_extensions=additional_extensions,
        logger=logger,
    ) as build_data:
        with preprocess_markdown(build_data) as files:
            opts = pandoc_options(build_data, OutputType.AST)
            files_str = " ".join(str(p) for p in files)
            output = Path(build_data.build_dir, "ast.json")
            temp_output = Path(build_data.temp_dir, "ast.json")
            sh(
                f"{build_data.pandoc} {opts} -o {temp_output} {files_str}",
                logger,
            )
            with (
                open(temp_output, mode="r", encoding="utf-8") as temp,
                open(output, mode="w", encoding="utf-8") as out,
            ):
                import json

                js = json.load(temp)
                out.write(json.dumps(js, sort_keys=False, indent=2))


def dump_combined(
    book_dir: Path,
    etc_dir: Path,
    additional_extensions: list[str],
    logger: logging.Logger,
) -> None:
    """
    Target: Dumps the combined single document to the build directory.

    Parameters:

    book_dir - the directory containing the book's sources
    etc_dir  - where the support files are located
    logger   - the logger
    """
    with prepare_build(
        book_dir=book_dir,
        etc_dir=etc_dir,
        additional_extensions=additional_extensions,
        logger=logger,
    ) as build_data:
        with preprocess_markdown(build_data) as files:
            output_path = Path(build_data.build_dir, "combined.md")
            logger.debug(f"Writing {output_path}")
            with open(output_path, mode="w", encoding="utf-8") as out:
                for file in files:
                    with open(file, mode="r", encoding="utf-8") as f:
                        out.write(f.read())


def copy_images_to_build(
    build_data: BuildData, logger: logging.Logger
) -> None:
    with chdir(build_data.book_dir):
        for img in build_data.image_references:
            if img.is_absolute():
                # Do nothing.
                continue

            parent = img.parent
            if str(parent) == ".":
                # Copy straight into build directory.
                target = Path(build_data.build_dir, img.name)

            else:
                # Relative copy.
                target_parent = Path(build_data.build_dir, parent)
                logger.debug(f"mkdir -p {target_parent}")
                target_parent.mkdir(parents=True, exist_ok=True)
                target = Path(build_data.build_dir, img)

            img_abs = Path(build_data.book_dir, img)
            logger.debug(f"Copying: {img_abs} -> {target}")
            shutil.copy(img_abs, target)


def build_html_or_pdf(
    build_data: BuildData, output_type: OutputType, logger: logging.Logger
) -> None:
    """
    Since PDF is built from HTML, building them is almost identical, except
    for a couple OutputType-related differences. This function builds either,
    based off the OutputType.

    Parameters:

    book_dir    - the directory containing the book's sources
    output_type - the output type (OutputType.PDF or OutputType.HTML)
    logger      - the logger
    """
    match output_type:
        case OutputType.PDF:
            extension = ".pdf"
            copy_images = False
        case OutputType.HTML:
            extension = ".html"
            copy_images = True
        case _:
            assert False

    with preprocess_markdown(build_data=build_data, divs=True) as files:
        files_str = " ".join(str(p) for p in files)
        output_path = Path(build_data.build_dir, f"book{extension}")
        logger.info(f'Building "{output_path}"')
        opts = pandoc_options(build_data, output_type)
        with chdir(build_data.book_dir):
            sh(
                f"{build_data.pandoc} {opts} -o {output_path} {files_str}",
                logger,
            )

    # HTML will want the images, so copy them into the output directory.
    if copy_images:
        copy_images_to_build(build_data, logger)


def build_docx(
    book_dir: Path,
    etc_dir: Path,
    additional_extensions: list[str],
    logger: logging.Logger,
) -> None:
    """
    Target: Creates the Microsoft Word version of the book

    Parameters:

    book_dir - the directory containing the book's sources
    logger   - the logger
    """
    with prepare_build(
        book_dir=book_dir,
        etc_dir=etc_dir,
        additional_extensions=additional_extensions,
        logger=logger,
    ) as build_data:
        with preprocess_markdown(build_data=build_data) as files:
            output_path = Path(build_data.build_dir, "book.docx")
            logger.info(f'Building "{output_path}"')
            opts = pandoc_options(build_data, OutputType.WORD)

            # Force-include the cover image, if there is one, because
            # Pandoc won't insert it.
            if build_data.source_paths.cover_image is not None:
                cover = make_temp_text_file(
                    "cover.md",
                    f"![]({build_data.source_paths.cover_image})",
                    build_data.temp_dir,
                )
                files = [cover] + files

            files_str = " ".join(str(p) for p in files)
            with chdir(build_data.book_dir):
                sh(
                    f"{build_data.pandoc} {opts} -o {output_path} {files_str}",
                    logger,
                )


def build_epub(
    book_dir: Path,
    etc_dir: Path,
    additional_extensions: list[str],
    logger: logging.Logger,
) -> None:
    """
    Target: Creates the ePub version of the book

    Parameters:

    book_dir - the directory containing the book's sources
    logger   - the logger
    """
    with prepare_build(
        book_dir=book_dir,
        etc_dir=etc_dir,
        additional_extensions=additional_extensions,
        logger=logger,
    ) as build_data:
        with preprocess_markdown(build_data=build_data) as files:
            files_str = " ".join(str(p) for p in files)
            output_path = Path(build_data.build_dir, "book.epub")
            logger.info(f'Building "{output_path}"')
            opts = pandoc_options(build_data, OutputType.EPUB)
            if build_data.source_paths.metadata is not None:
                metadata = load_metadata(build_data.source_paths.metadata)
            else:
                metadata = {}
            with chdir(build_data.book_dir):
                sh(
                    f"{build_data.pandoc} {opts} -o {output_path} {files_str}",
                    logger,
                )
                fix_epub(
                    epub=output_path,
                    build_data=build_data,
                    book_title=metadata.get("title", ""),
                    logger=logger,
                )


def build_html(
    book_dir: Path,
    etc_dir: Path,
    additional_extensions: list[str],
    logger: logging.Logger,
) -> None:
    """
    Target: Creates the HTML version of the book

    Parameters:

    book_dir - the directory containing the book's sources
    logger   - the logger
    """
    with prepare_build(
        book_dir=book_dir,
        etc_dir=etc_dir,
        additional_extensions=additional_extensions,
        logger=logger,
    ) as build_data:
        build_html_or_pdf(build_data, OutputType.HTML, logger)


def build_pdf(
    book_dir: Path,
    etc_dir: Path,
    additional_extensions: list[str],
    logger: logging.Logger,
) -> None:
    """
    Target: Creates the PDF version of the book

    Parameters:

    book_dir - the directory containing the book's sources
    logger   - the logger
    """
    with prepare_build(
        book_dir=book_dir,
        etc_dir=etc_dir,
        additional_extensions=additional_extensions,
        logger=logger,
    ) as build_data:
        build_html_or_pdf(build_data, OutputType.PDF, logger)


def build_all(
    book_dir: Path,
    etc_dir: Path,
    additional_extensions: list[str],
    logger: logging.Logger,
) -> None:
    for func in (build_pdf, build_html, build_epub, build_docx):
        func(
            book_dir=book_dir,
            etc_dir=etc_dir,
            additional_extensions=additional_extensions,
            logger=logger,
        )


def clean_output(
    book_dir: Path, etc_dir: Path, logger: logging.Logger
) -> None:
    build_dir = build_directory(book_dir)
    if build_dir.exists():
        logger.debug(f'Removing "{build_dir}" and its contents.')
        shutil.rmtree(build_dir)


@click.command("build")
@click.option(
    "-e",
    "--etc-dir",
    default=None,
    envvar="EBOOK_ETC_DIR",
    required=True,
    type=click.Path(dir_okay=True, file_okay=False, exists=True),
    help="Path to directory containing ebook's default templates, "
    "scripts, and other files. If not specified, the value "
    "of the EBOOK_ETC_DIR environment variable is used.",
)
@click.option(
    "-l",
    "--log-level",
    default="INFO",
    type=click.Choice(LOG_LEVELS, case_sensitive=False),
    help="Specify log level.",
    show_default=True,
)
@click.option(
    "-L",
    "--log-path",
    default=None,
    type=click.Path(dir_okay=False, writable=True),
    help="Path to additional file to which to log messages.",
)
@click.option(
    "-x",
    "--extensions",
    default=None,
    help="Comma-separated list of additional Pandoc Mardown "
    "extensions to be enabled",
)
@click.version_option(VERSION, prog_name=NAME)
@click.argument(
    "book_dir",
    required=True,
    type=click.Path(
        dir_okay=True, file_okay=False, writable=True, exists=True
    ),
)
@click.argument("target", required=False, nargs=-1)
def run_build(
    etc_dir: str,
    log_level: str,
    log_path: Optional[str],
    book_dir: str,
    extensions: Optional[str],
    target: str,
) -> None:
    """
    Build the ebook. BOOKDIR is the directory containing your book's
    sources. The output will be created in a "build" subdirectory.
    TARGET is the build target, as described below. You can specify multiple
    targets. The default TARGET is "all".

    Note that you must have properly installed the program (via the
    ./install.py script in the source repository) first.

    Valid build targets:

    clean: Clean up (remove) all built artifacts from BOOKDIR/build.

    build: Build all versions of the book (PDF, Epub, HTML, etc.) in directory
    BOOKDIR build

    pdf: Build just the PDF version of the book

    html: Build just the HTML version of the book

    epub: Build just the ePub version of the book

    docx: Build just the Microsoft Word version of the book

    ast: Write the Pandoc AST (as JSON), pretty-printed, to BOOKDIR/ast.json.
    This target is primarily for debugging this program.

    combined: Write the final combined document, as fed to Pandoc, to
    BOOKDIR/combined.md. Primarily for debugging.

    Default: build
    """
    logger = configure_logging(log_level.upper(), log_path)
    try:
        target_map = {
            "clean": clean_output,
            "all": build_all,
            "pdf": build_pdf,
            "epub": build_epub,
            "docx": build_docx,
            "word": build_docx,
            "html": build_html,
            "combined": dump_combined,
            "ast": dump_ast,
        }

        targets = target if len(target) > 0 else ["all"]

        # Validate targets first. Don't run anything unless we know all targets are
        # valid.
        target_funcs = []
        for t in targets:
            if (target_func := target_map.get(t)) is None:
                raise click.ClickException(f'"{t}" is an unknown target.')

            target_funcs.append(target_func)

        additional_extensions = []
        if extensions is not None:
            additional_extensions = [s.strip() for s in extensions.split(",")]

        for target_func in target_funcs:
            target_func(
                book_dir=Path(book_dir).absolute(),
                etc_dir=Path(etc_dir).absolute(),
                additional_extensions=additional_extensions,
                logger=logger,
            )
    except (BookError, FileNotFoundError) as e:
        logger.error(f"{e}")
        raise click.ClickException("--- ABORTED ---")


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    if sys.version_info < MIN_PYTHON_VERSION:
        s_ver = ".".join(str(n) for n in MIN_PYTHON_VERSION)
        print(
            f"Python {s_ver}.0 or better is required. You're using "
            f"{sys.version}"
        )
        sys.exit(1)

    run_build()
